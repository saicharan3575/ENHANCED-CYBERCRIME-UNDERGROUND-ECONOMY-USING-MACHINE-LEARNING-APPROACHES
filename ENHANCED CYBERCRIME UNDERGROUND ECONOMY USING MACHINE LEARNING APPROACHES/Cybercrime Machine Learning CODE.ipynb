{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import messagebox from tkinter import *\n",
    "from tkinter import simpledialog import tkinter\n",
    "from tkinter import filedialog\n",
    "from tkinter.filedialog import askopenfilename import numpy as np\n",
    "import matplotlib.pyplot as plt import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split import os\n",
    "from sklearn.metrics import confusion_matrix from sklearn.metrics import accuracy_score from sklearn.naive_bayes import GaussianNB\n",
    " \n",
    "from sklearn.metrics import precision_score from sklearn.metrics import recall_score from sklearn.metrics import f1_score import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import normalize from imblearn.over_sampling import SMOTE import pickle\n",
    "global filename, le global X,Y\n",
    "global dataset global main global text accuracy = [] precision = [] recall = [] fscore = []\n",
    "global X_train, X_test, y_train, y_test, predict_cls global classifier\n",
    "main = tkinter.Tk()\n",
    "main.title(\"Enhanced CyberCrime Underground Economy Using Machine Learning Approaches\") #designing main screen\n",
    "main.geometry(\"1300x1200\")\n",
    "labels = ['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'Infilteration', 'SQL Injection'] #fucntion to upload dataset\n",
    "def uploadDataset(): global filename global dataset\n",
    "text.delete('1.0', END)\n",
    "filename = filedialog.askopenfilename(initialdir=\"Dataset\") text.insert(END,filename+\" loaded\\n\\n\")\n",
    "dataset = pd.read_csv(filename) #replace missing values with 0\n",
    " \n",
    "dataset.fillna(0, inplace = True) text.insert(END,\"Dataset before preprocessing\\n\\n\") text.insert(END,str(dataset.head())+\"\\n\\n\")\n",
    "unique, count = np.unique(dataset['Label'], return_counts=True) for i in range(len(unique)):\n",
    "text.insert(END,str(unique[i])+\" = \"+str(count[i])+\"\\n\") text.update_idletasks()\n",
    "label = dataset.groupby('Label').size() label.plot(kind=\"bar\") plt.xlabel('Various Cybercrime Attacks') plt.ylabel('Count')\n",
    "plt.title('Cybercrime Graph') plt.show()\n",
    "#function to perform dataset preprocessing def analyticalProcessing():\n",
    "global X, Y, le global dataset\n",
    "global X_train, X_test, y_train, y_test text.delete('1.0', END)\n",
    "dataset.drop(columns=['Timestamp','Flow Byts/s','Flow Pkts/s'],inplace=True) le = LabelEncoder()\n",
    "dataset['Label'] = pd.Series(le.fit_transform(dataset['Label'].astype(str))) dataset = dataset.values\n",
    "X = dataset[:,0:dataset.shape[1]-1] Y = dataset[:,dataset.shape[1]-1] indices = np.arange(X.shape[0]) np.random.shuffle(indices)\n",
    "X = X[indices] Y = Y[indices]\n",
    "sm = SMOTE(random_state=42)\n",
    "smote_X, smote_Y = sm.fit_resample(X, Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(smote_X, smote_Y, test_size=0.2,\n",
    " \n",
    "random_state=0) print(Y) print(X)\n",
    "text.insert(END,\"Dataset after Preprocessing\\n\\n\") text.insert(END,str(X)+\"\\n\\n\")\n",
    "text.insert(END,\"Total records found in dataset : \"+str(X.shape[0])+\"\\n\") text.insert(END,\"Total features found in dataset: \"+str(X.shape[1])+\"\\n\\n\") text.insert(END,\"Dataset Train and Test Split\\n\\n\")\n",
    "text.insert(END,\"80% dataset records used to train Naive Bayes algorithms : \"+str(X_train.shape[0])+\"\\n\")\n",
    "text.insert(END,\"20% dataset records used to train Naive Bayes algorithms : \"+str(X_test.shape[0])+\"\\n\")\n",
    "def calculateMetrics(algorithm, predict, y_test): a = accuracy_score(y_test,predict)*100\n",
    "p = precision_score(y_test, predict,average='macro') * 100 r = recall_score(y_test, predict,average='macro') * 100\n",
    "f = f1_score(y_test, predict,average='macro') * 100 accuracy.append(a)\n",
    "precision.append(p) recall.append(r) fscore.append(f)\n",
    "text.insert(END,algorithm+\" Accuracy : \"+str(a)+\"\\n\") text.insert(END,algorithm+\" Precision : \"+str(p)+\"\\n\") text.insert(END,algorithm+\" Recall\t: \"+str(r)+\"\\n\") text.insert(END,algorithm+\" FScore\t\t: \"+str(f)+\"\\n\\n\")\n",
    "def runNaiveBayes():\n",
    "global X,Y, X_train, X_test, y_train, y_test, classifier global accuracy, precision,recall, fscore accuracy.clear()\n",
    "precision.clear() recall.clear() fscore.clear() text.delete('1.0', END)\n",
    " \n",
    "if os.path.exists('model/nb.txt'):\n",
    "with open('model/nb.txt', 'rb') as file:\n",
    "classifier = pickle.load(file) file.close()\n",
    "else:\n",
    "classifier = GaussianNB() classifier.fit(X, Y)\n",
    "with open('model/nb.txt', 'wb') as file: pickle.dump(classifier, file) file.close()\n",
    "predict = classifier.predict(X_test) calculateMetrics(\"Naive Bayes\", predict, y_test)\n",
    "def predict(): global classifier\n",
    "text.delete('1.0', END)\n",
    "filename = filedialog.askopenfilename(initialdir=\"Dataset\") text.insert(END,filename+\" loaded\\n\\n\")\n",
    "dataset = pd.read_csv(filename,encoding='iso-8859-1') dataset.fillna(0, inplace = True)\n",
    "dataset.drop(columns=['Timestamp','Flow Byts/s','Flow Pkts/s'],inplace=True) dataset = dataset.values\n",
    "prediction = classifier.predict(dataset) print(prediction)\n",
    "for i in range(len(prediction)):\n",
    "text.insert(END,\"Test DATA : \"+str(dataset[i])+\" ===> PREDICTED AS \"+labels[int(prediction[i])]+\"\\n\\n\")\n",
    "def graph():\n",
    "\n",
    "df = pd.DataFrame([['Naive Bayes','Precision',precision[0]],['Naive Bayes','Recall',recall[0]],['Naive Bayes','F1 Score',fscore[0]],['Naive Bayes','Accuracy',accuracy[0]], columns=['Algorithms','Performance Output','Value'])\n",
    "df.pivot(\"Algorithms\", \"Performance Output\", \"Value\").plot(kind='bar')\n",
    " \n",
    "plt.show() def close():\n",
    "main.destroy()\n",
    "font = ('times', 16, 'bold')\n",
    "title = Label(main, text='Enhanced CyberCrime Underground Economy Using Machine Learning Approaches')\n",
    "title.config(bg='greenyellow', fg='dodger blue') title.config(font=font)\n",
    "title.config(height=3, width=120) title.place(x=0,y=5)\n",
    "font1 = ('times', 12, 'bold') text=Text(main,height=20,width=150) scroll=Scrollbar(text) text.configure(yscrollcommand=scroll.set) text.place(x=50,y=120) text.config(font=font1)\n",
    "font1 = ('times', 13, 'bold')\n",
    "uploadButton = Button(main, text=\"Dataset Upload & Analysis\", command=uploadDataset) uploadButton.place(x=50,y=550)\n",
    "uploadButton.config(font=font1)\n",
    "processButton = Button(main, text=\"Dataset Processing & Analytical Methods\", command=analyticalProcessing)\n",
    "processButton.place(x=370,y=550) processButton.config(font=font1)\n",
    "nbButton = Button(main, text=\"Run Naive Bayes Classification Model\", command=runNaiveBayes)\n",
    "nbButton.place(x=750,y=550) nbButton.config(font=font1)\n",
    "graphButton = Button(main, text=\"Classification Performance Graph\", command=graph) graphButton.place(x=50,y=600)\n",
    "graphButton.config(font=font1)\n",
    "predictButton = Button(main, text=\"Predict Cyber Crime\", command=predict) predictButton.place(x=370,y=600)\n",
    "predictButton.config(font=font1)\n",
    " \n",
    "closeButton = Button(main, text=\"Exit\", command=close) closeButton.place(x=750,y=600) closeButton.config(font=font1) main.config(bg='LightSkyBlue')\n",
    "main.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
